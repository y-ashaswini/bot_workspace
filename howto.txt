# create package

> directory_name
>> src
>>> package_name

# write command + list dependenies
catkin_create_pkg std_msgs roscpp

# edit package.xml, CMakeLists.txt

> package_name
>> src
>>> file_one.cpp
>>> file_two.cpp
>> msgs
>>> message_name.msg

----------------------------------------------------------------

# Run robot with presaved configurations in rviz and gazebo

source /devel/setup.bash
roscore

roslauch fourbot world.launch
# launches both rviz and gaezbo (how to reopen saved rviz config)

rosrun teleop_twist_keyboard teleop_twist_keyboard.py cmd_vel:=/fourbot/cmd_vel
# control on robot movement on gazebo


# Topics published 

MISC
/clicked_point
/clock

CAMERA
/fourbot/camera/parameter_descriptions
/fourbot/camera/parameter_updates
/fourbot/camera/rgb/camera_info
/fourbot/camera/rgb/image_raw
/fourbot/camera/rgb/image_raw/compressed
/fourbot/camera/rgb/image_raw/compressed/parameter_descriptions
/fourbot/camera/rgb/image_raw/compressed/parameter_updates
/fourbot/camera/rgb/image_raw/compressedDepth
/fourbot/camera/rgb/image_raw/compressedDepth/parameter_descriptions
/fourbot/camera/rgb/image_raw/compressedDepth/parameter_updates
/fourbot/camera/rgb/image_raw/theora
/fourbot/camera/rgb/image_raw/theora/parameter_descriptions
/fourbot/camera/rgb/image_raw/theora/parameter_updates

GAZEBO
/gazebo/link_states
/gazebo/model_states
/gazebo/parameter_descriptions
/gazebo/parameter_updates
/gazebo/performance_metrics
/gazebo/set_link_state
/gazebo/set_model_state

ODOM
/fourbot/cmd_vel
/fourbot/odom
/initialpose
/joint_states
/move_base_simple/goal
/imu ------------------

/rosout
/rosout_agg
/tf
/tf_static




roslaunch vision color_detection_publisher.launch
rostopic list (you'll see webcam)
rostopic info /webcam (you'll see Image type, etc.)
rqt_image_view (switch to topic /webcam)



To add a plugin:
1) Add plugin code to packagename.gazebo within the <gazebo></gazebo> tags 
2) add link + joint to packagename.xacro [include it in the structure]

After adding depth sensor, topics published:

/depthcam/color/camera_info
/depthcam/color/image_raw ------------------
/depthcam/color/image_raw/compressed
/depthcam/color/image_raw/compressed/parameter_descriptions
/depthcam/color/image_raw/compressed/parameter_updates
/depthcam/color/image_raw/compressedDepth
/depthcam/color/image_raw/compressedDepth/parameter_descriptions
/depthcam/color/image_raw/compressedDepth/parameter_updates
/depthcam/color/image_raw/theora
/depthcam/color/image_raw/theora/parameter_descriptions
/depthcam/color/image_raw/theora/parameter_updates
/depthcam/depth/camera_info
/depthcam/depth/image_raw
/depthcam/depth/points ------------------
/depthcam_ir/depth/camera_info
/depthcam_ir/parameter_descriptions
/depthcam_ir/parameter_updates


SCRIPTS TO RUN FOR TRAVERSAL

>>> roslaunch fourbot rviz_gazebo.launch
>>> rosrun vision depth_node.py (depthcam/color/distance_opencv -- publishes distance from center of camera frame )
>>> rosrun vision fake_arrow.py -- detects arrow and publishes direction (hard coded currently)
>>> rosrun fourbot movement_depth.py -- moves forward, turns anticlockwise 30 deg (default) if distance < 1.8 units



ODOM
/fourbot/odom
/fourbot/imu
/fourbot/gps

Sample Data >

header: 
  seq: 21549
  stamp: 
    secs: 2240
    nsecs: 575000000
  frame_id: "odom"
child_frame_id: "robot_footprint"
pose: 
  pose: 
    position: 
      x: -3.603781907032657
      y: -8.712173282306216
      z: 0.0
    orientation: 
      x: -3.9998267267744516e-07
      y: 1.0721680793585594e-08
      z: 0.9798848351509343
      w: 0.1995637989242201
  covariance: [0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1000000000000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1000000000000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1000000000000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01]
twist: 
  twist: 
    linear: 
      x: -2.2812691466686442e-08
      y: 4.320901034244061e-11
      z: 0.0
    angular: 
      x: 0.0
      y: 0.0
      z: -1.972875243643067e-11
  covariance: [0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1000000000000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1000000000000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1000000000000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01]


----------------------------------------------------------------

https://prabhjotkaurgosal.com/a-guide-to-implementing-ros-navigation-stack-on-your-robot/4/

GMAPPING (creating and saving a map)

> roslaunch fourbot temp.launch
> roslaunch fourbot gmapping_launch.launch (maps, save map)
> rosrun teleop_twist_keyboard teleop_twist_keyboard.py cmd_vel:=/fourbot/cmd_vel
[go around the place, map it out, save, relaunch world, launch amcl node (haven't created one here yet), travel, etc.]


RUNNING WITH MAP + AMCL NODE 

> roslaunch fourbot temp.launch
> roslaunch fourbot temp_amcl_map.launch (will launch amc node, so go to rviz and select /pointcloud)
> (go to directory) ./init_pose_estimate.launch (for estimating pose without interacting directly with rviz)
> rosrun teleop_twist_keyboard teleop_twist_keyboard.py cmd_vel:=/fourbot/cmd_vel (to go around a little bit and let it do the localisation by itself)


PATH PLANNING - MOVEBASE

http://wiki.ros.org/global_planner?distro=noetic


- firstly, costmaps have to be initialized.
- this can be done either by providing the static map from map_server node or by providing a fixed width and height of the region
- global planner: creating long-term plans over the entire environment
- local planner: creates short term plans, taking into account the obstacle information in the environment
- for via map (and without map?), must use with amcl_node to give it info about obstacles
- the navigation stack uses information from sensors to avoid obstacles in the world, it assumes that these sensors are publishing either sensor_msgs/LaserScan or sensor_msgs/PointCloud messages over ROS


- set parameters for move_base node in yaml files
- separate costmap params for local and global, and 1 with params common to both


> roslaunch fourbot temp.launch (gazebo + rviz)
> roslaunch fourbot temp_trav_combined.launch (map server + amcl, movebase) --- WHEN NO MAP

move base topics:

/move_base/NavfnROS/plan
/move_base/TrajectoryPlannerROS/cost_cloud
/move_base/TrajectoryPlannerROS/global_plan
/move_base/TrajectoryPlannerROS/local_plan
/move_base/TrajectoryPlannerROS/parameter_descriptions
/move_base/TrajectoryPlannerROS/parameter_updates
/move_base/cancel
/move_base/current_goal
/move_base/feedback
/move_base/global_costmap/costmap
/move_base/global_costmap/costmap_updates
/move_base/global_costmap/footprint
/move_base/global_costmap/inflation_layer/parameter_descriptions
/move_base/global_costmap/inflation_layer/parameter_updates
/move_base/global_costmap/obstacle_layer/parameter_descriptions
/move_base/global_costmap/obstacle_layer/parameter_updates
/move_base/global_costmap/parameter_descriptions
/move_base/global_costmap/parameter_updates
/move_base/global_costmap/static_layer/parameter_descriptions
/move_base/global_costmap/static_layer/parameter_updates
/move_base/goal
/move_base/local_costmap/costmap
/move_base/local_costmap/costmap_updates
/move_base/local_costmap/footprint
/move_base/local_costmap/inflation_layer/parameter_descriptions
/move_base/local_costmap/inflation_layer/parameter_updates
/move_base/local_costmap/obstacle_layer/parameter_descriptions
/move_base/local_costmap/obstacle_layer/parameter_updates
/move_base/local_costmap/parameter_descriptions
/move_base/local_costmap/parameter_updates
/move_base/parameter_descriptions
/move_base/parameter_updates
/move_base/recovery_status
/move_base/result
/move_base/status
/move_base_simple/goal


this is WITH A MAP CURRENTLY. need to do one without a map.

----------------------------------------------------------------


WITHOUT A MAP - DONE

- fourbot
- gmapping
- amcl
- movebase

> roslaunch fourbot movebase_combined.launch
only works when you run that script that publishes move_base goals too - uses dwa, dijkstra, and works! WEEE.
> cd onbot_ws/src/simple_navigation_goals/src
> ./simple_navigation_goals.py (made a script launch.launch but cannot see logs for some reason idk why)

----------------------------------------------------------------

TODO

* recovery behavior - move to last safe position (how?)
* keep moving forward (or wherever optimal position) until goal reached - custom script - in progress
* add depthcam (simulate intel realsense)
* integrate arrow detection algorithm into it
* make a document on how to do all this on a real bot
  (
    > how to communicate with wheel encoders?
    > gps and imu - kalman filter - implementation?
    > realsense drivers?
    > without simulation, how control, observe?
    > also, how to send data from ros to the gcs website?
  )


realsense d435 ros plugin:
https://github.com/pal-robotics/realsense_gazebo_plugin - plugin usage(?) on github
http://wiki.ros.org/realsense2_camera - roswiki page
https://github.com/IntelRealSense/realsense-ros/tree/ros1-legacy - installation instructions (for ros 1)

----------------------------------------------------------------

https://github.com/MarkNaeem/move_base_sequence/blob/main/src/server.py
